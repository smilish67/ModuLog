# 1. 파인 튜닝 가이드

## 1) pyannote 파인튜닝 for speaker diarizaiton purpose
pyannote는 [pyannote.audio](https://github.com/pyannote/pyannote-audio/tree/main/tutorials)의 파인튜닝 가이드를 참고하였습니다. <br>
pyannote의 speaker diarization pipeline을 보유하신 데이터셋에 맞게 파인튜닝하는 과정은 다음과 같습니다.  
- Pyannote-segmentation 모델 파인튜닝
- Optimizing the pipeline hyper-parameters

본 가이드라인을 따르기 위해서는, 데이터셋을 다음과 같이 구성해야 합니다. ([pyannote.database](https://github.com/pyannote/pyannote-database) 참고) <br>
데이터셋 별로 포맷 변경에 필요한 작업이 다를 수 있기 때문에, 저희가 사용한 데이터셋을 포맷변환한 내용을 공유하겠습니다. (utils 폴더 내)

- dataset
    - train.txt (각 txt 파일에는 각 세트에 해당하는 데이터의 uri가 담깁니다.(파일명))
    - dev.txt
    - test.txt
    - train (학습 용도) 
        - wav (or else) folder
            - {uri}.wav
        - rttm folder
            - {uri}.rttm
        - uem folder
            - {uri}.uem
    - dev (pipeline hyper-parameters optimize 용도)
        - 동일
    - test (테스트)
        - 동일

## 2) NeMo 파인튜닝 [[상세 기록 Link]](https://github.com/Hyeji-Jo/modu/blob/3d33cc6c82ddc20cbbf5d31615e04a3a545cbf26/docs/fine_tuning/Pyannote_%EC%84%B1%EB%8A%A5%EC%83%81%EC%84%B8.md)


# 2. 파인튜닝 성능  
- loss/val/segmentation
    - 검증 데이터에서 segmentation loss - 음성 분할 관련 손실
    - 낮을수록 모델이 더 정확하게 분할됨
- loss/val/vad
    - 검증 데이터에서 음성 활동 감지 (VAD) loss 값
- loss/val
    - 전체 검증 loss 값
    - 작을수록 모델이 더 정확함
- DiarizationErrorRate
    - 전체 화자인식 오류율(DER)
    - 작을수록 좋음
- DiarizationErrorRate/Confusion
    - 화자 간 혼동률 - 잘못된 화자 매칭 비율
    - 낮을수록 좋음
- DiarizationErrorRate/FalseAlarm
    - 음성이 없는데 있다고 감지한 비율
    - 낮을수록 좋음
- DiarizationErrorRate/Miss
    - 놓친 음성 비율
    - 낮을수록 좋음
- DiarizationErrorRate/Threshold
    - DER 계산 시 사용된 임계값

## 1) Adam + 20epoch  
  
|  Epoch | loss/val/segmentation | loss/val/vad | loss/val | DiarizationErrorRate | Confusion | FalseAlarm | Miss | Threshold |
|--------|----------------------|--------------|----------|----------------------|-----------|------------|------|-----------|
| 0      | 0.40065              | 0.488325     | 0.88895  | 0.6246               | 0.03265   | 0.05255    | 0.5398 | 0.6300    |
| 1      | 0.2192               | 0.24385      | 0.46305  | 0.2501               | 0.0352    | 0.0796     | 0.1353 | 0.6200    |
| 2      | 0.20745              | 0.2365       | 0.44385  | 0.2402               | 0.0311    | 0.0781     | 0.1311 | 0.5800    |
| ...     | ...             | ...      | ...   | ...               | ...    | ...     | ... | ...    |
| 15     | 0.189                | 0.22365      | 0.41265  | 0.2207               | 0.0253    | 0.0746     | 0.1208 | 0.5600    |
| 16     | 0.18815              | 0.223        | 0.4112   | 0.2196               | 0.0249    | 0.0768     | 0.1180 | 0.5600    |
| 17     | 0.18885              | 0.2245       | 0.4133   | 0.2191               | 0.0249    | 0.0759     | 0.1183 | 0.5800    |
| 18     | 0.1892               | 0.22435      | 0.4136   | 0.2191               | 0.0249    | 0.0729     | 0.1213 | 0.5800    |
| 19     | 0.18755              | 0.22245      | 0.41     | 0.2181               | 0.0244    | 0.0755     | 0.1182 | 0.5600    |


## 2) AdamW + 20epoch  
  
|    |   loss/val/segmentation |   loss/val/vad |   loss/val |   DiarizationErrorRate |   Confusion |   FalseAlarm |   Miss |   Threshold |   loss/train/segmentation |   loss/train/vad |   loss/train |
|----|-------------------------|----------------|------------|------------------------|----------------------------------|-----------------------------------|-----------------------------|----------------------------------|---------------------------|------------------|--------------|
|  0 |                 0.39935 |       0.431175 |    0.8305  |                0.39435 |                          0.03865 |                           0.09995 |                      0.2557 |                             0.57 |                 nan       |        nan       |    nan       |
|  1 |                 0.2193  |       0.24265  |    0.46195 |                0.2545  |                          0.0359  |                           0.0849  |                      0.1337 |                             0.6  |                   0.28875 |          0.2774  |      0.56615 |
|  2 |                 0.21015 |       0.23805  |    0.44815 |                0.2464  |                          0.0329  |                           0.081   |                      0.1326 |                             0.58 |                   0.22295 |          0.2418  |      0.46475 |
| ...     | ...             | ...      | ...   | ...               | ...    | ...     | ... | ...    |
| 15 |                 0.18815 |       0.2228   |    0.4109  |                0.2219  |                          0.0253  |                           0.074   |                      0.1226 |                             0.56 |                   0.1765  |          0.20885 |      0.38535 |
| 16 |                 0.18895 |       0.22285  |    0.4118  |                0.2215  |                          0.0251  |                           0.0756  |                      0.1209 |                             0.58 |                   0.17485 |          0.2074  |      0.38225 |
| 17 |                 0.1881  |       0.22225  |    0.41035 |                0.2199  |                          0.0249  |                           0.0765  |                      0.1186 |                             0.58 |                   0.1736  |          0.2059  |      0.37955 |
| 18 |                 0.18835 |       0.2233   |    0.41165 |                0.2204  |                          0.0246  |                           0.0758  |                      0.12   |                             0.58 |                   0.17325 |          0.2063  |      0.3795  |
| 19 |                 0.1878  |       0.22205  |    0.4098  |                0.2198  |                          0.0244  |                           0.0771  |                      0.1183 |                             0.58 |                   0.17225 |          0.20485 |      0.3771  |

## 3) RAdam (Rectified Adam)  
  
|    |   loss/val/segmentation |   loss/val/vad |   loss/val |   DiarizationErrorRate |   Confusion |   FalseAlarm |   Miss |   Threshold |   loss/train/segmentation |   loss/train/vad |   loss/train |
|----|-------------------------|----------------|------------|------------------------|----------------------------------|-----------------------------------|-----------------------------|----------------------------------|---------------------------|------------------|--------------|
|  0 |                 0.3967  |       0.439475 |   0.836175 |                 0.5042 |                           0.0335 |                            0.1178 |                     0.35285 |                             0.58 |                 nan       |        nan       |    nan       |
|  1 |                 0.2132  |       0.24265  |   0.45575  |                 0.2457 |                           0.0335 |                            0.0806 |                     0.1316  |                             0.6  |                   0.32425 |          0.3309  |      0.65515 |
|  2 |                 0.20605 |       0.23705  |   0.44305  |                 0.2396 |                           0.0315 |                            0.0791 |                     0.129   |                             0.58 |                   0.21145 |          0.24345 |      0.45495 |
| ...     | ...             | ...      | ...   | ...               | ...    | ...     | ... | ...    |
| 15 |                 0.18935 |       0.2221   |   0.41155  |                 0.2213 |                           0.0257 |                            0.0774 |                     0.1182  |                             0.56 |                   0.17605 |          0.2093  |      0.3854  |
| 16 |                 0.18845 |       0.2224   |   0.4109   |                 0.2212 |                           0.0252 |                            0.0749 |                     0.121   |                             0.58 |                   0.1745  |          0.2082  |      0.3827  |
| 17 |                 0.18865 |       0.2225   |   0.41115  |                 0.2203 |                           0.025  |                            0.0758 |                     0.1195  |                             0.58 |                   0.17365 |          0.2065  |      0.38015 |
| 18 |                 0.1898  |       0.2235   |   0.4133   |                 0.2205 |                           0.0252 |                            0.0776 |                     0.1177  |                             0.58 |                   0.173   |          0.2068  |      0.3798  |
| 19 |                 0.1877  |       0.2226   |   0.41035  |                 0.2199 |                           0.0247 |                            0.076  |                     0.1192  |                             0.58 |                   0.17215 |          0.2054  |      0.3776  |

## 4) RAdam + CosineAnnealing  
  
|    |   loss/val/segmentation |   loss/val/vad |   loss/val |   DiarizationErrorRate |   Confusion |   FalseAlarm |   Miss |   Threshold |   loss/train/segmentation |   loss/train/vad |   loss/train |
|----|-------------------------|----------------|------------|------------------------|----------------------------------|-----------------------------------|-----------------------------|----------------------------------|---------------------------|------------------|--------------|
|  0 |                0.407775 |        0.44465 |    0.8524  |                 0.4676 |                           0.0582 |                           0.21605 |                      0.1934 |                             0.58 |                 nan       |        nan       |    nan       |
|  1 |                0.22825  |        0.2513  |    0.47955 |                 0.2611 |                           0.0377 |                           0.086   |                      0.1374 |                             0.62 |                   0.35855 |          0.35595 |      0.71445 |
|  2 |                0.21315  |        0.24115 |    0.4543  |                 0.2472 |                           0.0332 |                           0.0793  |                      0.1348 |                             0.6  |                   0.2303  |          0.2524  |      0.4827  |
| ...     | ...             | ...      | ...   | ...               | ...    | ...     | ... | ...    |
| 15 |                0.19305  |        0.22595 |    0.419   |                 0.2255 |                           0.0265 |                           0.0783  |                      0.1207 |                             0.56 |                   0.18125 |          0.21445 |      0.39565 |
| 16 |                0.1929   |        0.22575 |    0.41865 |                 0.2255 |                           0.0265 |                           0.0776  |                      0.1215 |                             0.56 |                   0.1801  |          0.21355 |      0.39365 |
| 17 |                0.1934   |        0.2258  |    0.4192  |                 0.2253 |                           0.0267 |                           0.0726  |                      0.126  |                             0.58 |                   0.17985 |          0.21255 |      0.3924  |
| 18 |                0.19305  |        0.22565 |    0.41865 |                 0.2253 |                           0.0265 |                           0.0777  |                      0.1212 |                             0.56 |                   0.1804  |          0.2139  |      0.3943  |
| 19 |                0.19315  |        0.2257  |    0.41885 |                 0.2253 |                           0.0266 |                           0.0725  |                      0.1261 |                             0.58 |                   0.17975 |          0.21295 |      0.3927  |


## 5) Adamw + CosineAnnealing (50 epoch)
|    |   loss/val/segmentation |   loss/val/vad |   loss/val |   DiarizationErrorRate |   Confusion |   FalseAlarm |   Miss |   Threshold |   loss/train/segmentation |   loss/train/vad |   loss/train |
|----|-------------------------|----------------|------------|------------------------|----------------------------------|-----------------------------------|-----------------------------|----------------------------------|---------------------------|------------------|--------------|
|  0 |                 0.441   |       0.406475 |   0.847475 |                0.53875 |                           0.0416 |                            0.1879 |                     0.30925 |                             0.62 |                 nan       |        nan       |    nan       |
|  1 |                 0.2112  |       0.2398   |   0.45095  |                0.243   |                           0.0337 |                            0.0794 |                     0.1299  |                             0.6  |                   0.2685  |          0.2786  |      0.54715 |
|  2 |                 0.204   |       0.23475  |   0.4387   |                0.237   |                           0.0314 |                            0.0809 |                     0.1247  |                             0.56 |                   0.2069  |          0.2383  |      0.4452  |
| ...     | ...             | ...      | ...   | ...               | ...    | ...     | ... | ...    |
| 45 |                 0.1861  |       0.22235  |   0.40845  |                0.2181  |                           0.024  |                            0.0753 |                     0.1188  |                             0.58 |                   0.16635 |          0.2001  |      0.3665  |
| 46 |                 0.1862  |       0.22235  |   0.4086   |                0.218   |                           0.0241 |                            0.0753 |                     0.1187  |                             0.58 |                   0.1662  |          0.1989  |      0.3651  |
| 47 |                 0.18625 |       0.22245  |   0.40865  |                0.2181  |                           0.0241 |                            0.0754 |                     0.1187  |                             0.58 |                   0.16625 |          0.19905 |      0.3653  |
| 48 |                 0.1862  |       0.2224   |   0.4086   |                0.2181  |                           0.0241 |                            0.0754 |                     0.1187  |                             0.58 |                   0.16635 |          0.20005 |      0.36645 |
| 49 |                 0.1862  |       0.22245  |   0.40865  |                0.2181  |                           0.0241 |                            0.0754 |                     0.1186  |                             0.58 |                   0.1673  |          0.2005  |      0.36785 |


## 6) Nadam + CosineAnnealing (50 epoch)  

|    |   loss/val/segmentation |   loss/val/vad |   loss/val |   DiarizationErrorRate |   Confusion |   FalseAlarm |   Miss |   Threshold |   loss/train/segmentation |   loss/train/vad |   loss/train |
|----|-------------------------|----------------|------------|------------------------|----------------------------------|-----------------------------------|-----------------------------|----------------------------------|---------------------------|------------------|--------------|
|  0 |                0.404125 |        0.4496  |   0.853725 |                 0.5296 |                          0.04725 |                            0.2442 |                      0.2381 |                             0.57 |                 nan       |        nan       |    nan       |
|  1 |                0.21055  |        0.2397  |   0.45025  |                 0.2414 |                          0.0329  |                            0.0806 |                      0.1279 |                             0.6  |                   0.26015 |          0.28095 |      0.54105 |
|  2 |                0.2033   |        0.23475 |   0.4381   |                 0.236  |                          0.0308  |                            0.0759 |                      0.1293 |                             0.58 |                   0.20635 |          0.23745 |      0.44385 |
| ...     | ...             | ...      | ...   | ...               | ...    | ...     | ... | ...    |
| 45 |                0.1849   |        0.2202  |   0.4051   |                 0.2171 |                          0.0237  |                            0.0727 |                      0.1207 |                             0.58 |                   0.166   |          0.2     |      0.366   |
| 46 |                0.18495  |        0.2202  |   0.40515  |                 0.2171 |                          0.0237  |                            0.0728 |                      0.1206 |                             0.58 |                   0.1659  |          0.19875 |      0.3647  |
| 47 |                0.1849   |        0.2202  |   0.40515  |                 0.2171 |                          0.0236  |                            0.0727 |                      0.1207 |                             0.58 |                   0.1661  |          0.19895 |      0.365   |
| 48 |                0.18495  |        0.2202  |   0.40515  |                 0.2171 |                          0.0236  |                            0.0731 |                      0.1204 |                             0.58 |                   0.1661  |          0.2001  |      0.36615 |
| 49 |                0.18495  |        0.2202  |   0.4052   |                 0.2171 |                          0.0236  |                            0.0731 |                      0.1204 |                             0.58 |                   0.167   |          0.2004  |      0.3674  |

## 7) Nadam + CosineAnnealing (50 epoch + batch_size = 128)  
  
|    |   loss/val/segmentation |   loss/val/vad |   loss/val |   DiarizationErrorRate |   Confusion |   FalseAlarm |   Miss |   Threshold |   loss/train/segmentation |   loss/train/vad |   loss/train |
|----|-------------------------|----------------|------------|------------------------|----------------------------------|-----------------------------------|-----------------------------|----------------------------------|---------------------------|------------------|--------------|
|  0 |                0.419375 |       0.371275 |   0.790675 |                0.35425 |                           0.0646 |                           0.08495 |                     0.20465 |                             0.59 |                 nan       |        nan       |    nan       |
|  1 |                0.22945  |       0.24975  |   0.4792   |                0.254   |                           0.0383 |                           0.0825  |                     0.1333  |                             0.6  |                   0.3045  |          0.30335 |      0.60785 |
|  2 |                0.21565  |       0.24295  |   0.45865  |                0.2454  |                           0.0347 |                           0.0783  |                     0.1324  |                             0.6  |                   0.23075 |          0.24645 |      0.47725 |
| ...     | ...             | ...      | ...   | ...               | ...    | ...     | ... | ...    |
| 45 |                0.1895   |       0.2237   |   0.4132   |                0.2201  |                           0.0254 |                           0.0731  |                     0.1217  |                             0.58 |                   0.17295 |          0.2056  |      0.3785  |
| 46 |                0.1894   |       0.22365  |   0.41305  |                0.2201  |                           0.0253 |                           0.073   |                     0.1218  |                             0.58 |                   0.17305 |          0.2043  |      0.37735 |
| 47 |                0.18945  |       0.22365  |   0.41315  |                0.2201  |                           0.0254 |                           0.073   |                     0.1217  |                             0.58 |                   0.17305 |          0.2044  |      0.37745 |
| 48 |                0.18945  |       0.22365  |   0.4131   |                0.2201  |                           0.0253 |                           0.0731  |                     0.1216  |                             0.58 |                   0.1735  |          0.2058  |      0.3793  |
| 49 |                0.1894   |       0.22365  |   0.41315  |                0.2201  |                           0.0253 |                           0.0731  |                     0.1216  |                             0.58 |                   0.1742  |          0.20625 |      0.3804  |


## 8) Nadam + CosineAnnealing (50 epoch + batch_size = 256)  

|    |   loss/val/segmentation |   loss/val/vad |   loss/val |   DiarizationErrorRate |   Confusion |   FalseAlarm |   Miss |   Threshold |   loss/train/segmentation |   loss/train/vad |   loss/train |
|----|-------------------------|----------------|------------|------------------------|----------------------------------|-----------------------------------|-----------------------------|----------------------------------|---------------------------|------------------|--------------|
|  0 |                 0.45195 |        0.4723  |    0.92425 |                 0.5248 |                           0.0721 |                            0.2229 |                      0.2298 |                             0.52 |                 nan       |        nan       |    nan       |
|  1 |                 0.25335 |        0.26015 |    0.51345 |                 0.2864 |                           0.0535 |                            0.0873 |                      0.1457 |                             0.62 |                   0.365   |          0.3525  |      0.7175  |
|  2 |                 0.2328  |        0.2514  |    0.48415 |                 0.2658 |                           0.0429 |                            0.0832 |                      0.1397 |                             0.6  |                   0.26305 |          0.2594  |      0.5224  |
| ...     | ...             | ...      | ...   | ...               | ...    | ...     | ... | ...    |
| 45 |                 0.19145 |        0.22445 |    0.41585 |                 0.2237 |                           0.0258 |                            0.0774 |                      0.1205 |                             0.56 |                   0.17765 |          0.2102  |      0.38785 |
| 46 |                 0.19135 |        0.2244  |    0.41575 |                 0.2237 |                           0.0258 |                            0.0777 |                      0.1202 |                             0.56 |                   0.1777  |          0.20885 |      0.38655 |
| 47 |                 0.19135 |        0.22445 |    0.41585 |                 0.2237 |                           0.0258 |                            0.0778 |                      0.1201 |                             0.56 |                   0.1777  |          0.20895 |      0.3866  |
| 48 |                 0.19135 |        0.2245  |    0.41585 |                 0.2237 |                           0.0258 |                            0.0781 |                      0.1198 |                             0.56 |                   0.17815 |          0.21045 |      0.3886  |
| 49 |                 0.19135 |        0.2245  |    0.41585 |                 0.2237 |                           0.0258 |                            0.0781 |                      0.1198 |                             0.56 |                   0.17895 |          0.21055 |      0.3895  |


## 9) Nadam + CosineAnnealing (50 epoch + 64 batch_size + bce_dice loss)  

|    |   loss/val/segmentation |   loss/val/vad |   loss/val |   DiarizationErrorRate |   Confusion |   FalseAlarm |   Miss |   Threshold |   loss/train/segmentation |   loss/train/vad |   loss/train |
|----|-------------------------|----------------|------------|------------------------|----------------------------------|-----------------------------------|-----------------------------|----------------------------------|---------------------------|------------------|--------------|
|  0 |                 0.43545 |       0.449125 |   0.884575 |                 0.525  |                          0.03945 |                            0.1897 |                     0.29585 |                             0.55 |                 nan       |        nan       |    nan       |
|  1 |                 0.20955 |       0.23855  |   0.44815  |                 0.2431 |                          0.0327  |                            0.0823 |                     0.1282  |                             0.56 |                   0.26445 |          0.276   |      0.54045 |
|  2 |                 0.20465 |       0.23355  |   0.4382   |                 0.2368 |                          0.0304  |                            0.078  |                     0.1283  |                             0.58 |                   0.20865 |          0.2379  |      0.4465  |
| ...     | ...             | ...      | ...   | ...               | ...    | ...     | ... | ...    |
| 40 |                 0.18525 |       0.2214   |   0.40665  |                 0.216  |                          0.0236  |                            0.0775 |                     0.1149  |                             0.56 |                   0.16665 |          0.19915 |      0.36575 |
| 41 |                 0.18525 |       0.22155  |   0.40685  |                 0.216  |                          0.0236  |                            0.0768 |                     0.1156  |                             0.56 |                   0.166   |          0.19825 |      0.36425 |
| 42 |                 0.1852  |       0.2214   |   0.4066   |                 0.2159 |                          0.0237  |                            0.0754 |                     0.1168  |                             0.56 |                   0.1658  |          0.1988  |      0.3646  |
| 43 |                 0.18535 |       0.2214   |   0.4067   |                 0.2158 |                          0.0237  |                            0.0762 |                     0.116   |                             0.56 |                   0.1658  |          0.1987  |      0.3645  |
| 44 |                 0.1851  |       0.22135  |   0.4065   |                 0.2159 |                          0.0237  |                            0.0761 |                     0.1162  |                             0.56 |                   0.16535 |          0.1988  |      0.36415 |
| 45 |                 0.1851  |       0.2214   |   0.40645  |                 0.2159 |                          0.0236  |                            0.0761 |                     0.1161  |                             0.56 |                   0.1659  |          0.1989  |      0.36485 |
| 46 |                 0.18505 |       0.2214   |   0.40645  |                 0.2159 |                          0.0237  |                            0.0761 |                     0.1161  |                             0.56 |                   0.1649  |          0.1969  |      0.36175 |
| 47 |                 0.1851  |       0.2214   |   0.40645  |                 0.2159 |                          0.0237  |                            0.0762 |                     0.1161  |                             0.56 |                   0.16605 |          0.19835 |      0.36435 |
| 48 |                 0.185   |       0.2213   |   0.40635  |                 0.2159 |                          0.0237  |                            0.076  |                     0.1162  |                             0.56 |                   0.16595 |          0.199   |      0.36495 |
| 49 |                 0.185   |       0.2213   |   0.40635  |                 0.2159 |                          0.0237  |                            0.0761 |                     0.1162  |                             0.56 |                   0.1665  |          0.1996  |      0.3661  |


## 10) Nadam + CosineAnnealing (50 epoch + 64 batch_size + bce_dice loss)  + Data Augmentation

|    |   loss/val/segmentation |   loss/val/vad |   loss/val |   DiarizationErrorRate |   Confusion |   FalseAlarm |   Miss |   Threshold |   loss/train/segmentation |   loss/train/vad |   loss/train |
|----|-------------------------|----------------|------------|------------------------|----------------------------------|-----------------------------------|-----------------------------|----------------------------------|---------------------------|------------------|--------------|
|  0 |                 0.48165 |       0.487817 |   0.969483 |                 0.5616 |                        0.0271667 |                            0.0983 |                    0.436167 |                         0.606667 |                 nan       |        nan       |    nan       |
|  1 |                 0.21385 |       0.24265  |   0.4565   |                 0.2473 |                        0.0349    |                            0.0802 |                    0.1322   |                         0.58     |                   0.28645 |          0.29645 |      0.58295 |
|  2 |                 0.20965 |       0.23985  |   0.44955  |                 0.2435 |                        0.0333    |                            0.0787 |                    0.1316   |                         0.58     |                   0.22715 |          0.25215 |      0.47925 |
| ...     | ...             | ...      | ...   | ...               | ...    | ...     | ... | ...    |
| 40 |                 0.1899  |       0.2247   |   0.41455  |                 0.2225 |                        0.0256    |                            0.0723 |                    0.1246   |                         0.58     |                   0.1959  |          0.2251  |      0.42095 |
| 41 |                 0.1903  |       0.22515  |   0.41545  |                 0.2226 |                        0.0256    |                            0.0736 |                    0.1233   |                         0.58     |                   0.1963  |          0.22455 |      0.4209  |
| 42 |                 0.1896  |       0.22485  |   0.41445  |                 0.2224 |                        0.0254    |                            0.0725 |                    0.1245   |                         0.58     |                   0.1951  |          0.2247  |      0.41985 |
| 43 |                 0.18985 |       0.22475  |   0.4146   |                 0.2226 |                        0.0255    |                            0.0712 |                    0.1258   |                         0.58     |                   0.1961  |          0.2246  |      0.42065 |
| 44 |                 0.18995 |       0.225    |   0.41495  |                 0.2226 |                        0.0255    |                            0.0726 |                    0.1245   |                         0.58     |                   0.19485 |          0.225   |      0.41985 |
| 45 |                 0.18985 |       0.22495  |   0.4148   |                 0.2225 |                        0.0254    |                            0.0724 |                    0.1247   |                         0.58     |                   0.1955  |          0.22405 |      0.4195  |
| 46 |                 0.18975 |       0.22485  |   0.4147   |                 0.2226 |                        0.0254    |                            0.0723 |                    0.1248   |                         0.58     |                   0.1947  |          0.22375 |      0.4185  |
| 47 |                 0.18975 |       0.22485  |   0.4146   |                 0.2225 |                        0.0254    |                            0.0721 |                    0.125    |                         0.58     |                   0.1958  |          0.2234  |      0.41915 |
| 48 |                 0.1897  |       0.22485  |   0.4145   |                 0.2226 |                        0.0254    |                            0.072  |                    0.1251   |                         0.58     |                   0.19585 |          0.22545 |      0.4213  |
| 49 |                 0.1897  |       0.22485  |   0.41455  |                 0.2225 |                        0.0254    |                            0.072  |                    0.1251   |                         0.58     |                   0.19585 |          0.2245  |      0.42035 |


## 11) Nadam + CosineAnnealing (50 epoch + 64 batch_size + bce_tversky loss)

|    |   loss/val/segmentation |   loss/val/vad |   loss/val |   DiarizationErrorRate |   Confusion |   FalseAlarm |   Miss |   Threshold |   loss/train/segmentation |   loss/train/vad |   loss/train |
|----|-------------------------|----------------|------------|------------------------|----------------------------------|-----------------------------------|-----------------------------|----------------------------------|---------------------------|------------------|--------------|
|  0 |                0.461325 |       0.404675 |    0.866   |                 0.4797 |                           0.0338 |                            0.1287 |                     0.31715 |                             0.64 |                 nan       |        nan       |    nan       |
|  1 |                0.21705  |       0.2432   |    0.46025 |                 0.2519 |                           0.0348 |                            0.0849 |                     0.1322  |                             0.58 |                   0.29545 |          0.2766  |      0.572   |
|  2 |                0.2096   |       0.2374   |    0.447   |                 0.2426 |                           0.0316 |                            0.0791 |                     0.1319  |                             0.6  |                   0.2176  |          0.24095 |      0.45865 |
| ...     | ...             | ...      | ...   | ...               | ...    | ...     | ... | ...    |
| 40 |                0.18555  |       0.22155  |    0.407   |                 0.2167 |                           0.0235 |                            0.0786 |                     0.1145  |                             0.56 |                   0.16595 |          0.19825 |      0.3642  |
| 41 |                0.1857   |       0.2218   |    0.4075  |                 0.2166 |                           0.0236 |                            0.0789 |                     0.1141  |                             0.56 |                   0.1662  |          0.1982  |      0.36445 |
| 42 |                0.1854   |       0.2216   |    0.407   |                 0.2166 |                           0.0235 |                            0.0779 |                     0.1152  |                             0.56 |                   0.16545 |          0.19845 |      0.3639  |
| 43 |                0.18555  |       0.2217   |    0.40725 |                 0.2168 |                           0.0237 |                            0.0759 |                     0.1173  |                             0.56 |                   0.16595 |          0.1982  |      0.3641  |
| 44 |                0.18555  |       0.222    |    0.4075  |                 0.2168 |                           0.0236 |                            0.0779 |                     0.1154  |                             0.56 |                   0.1648  |          0.1982  |      0.363   |
| 45 |                0.18565  |       0.22195  |    0.4076  |                 0.2168 |                           0.0236 |                            0.0781 |                     0.1151  |                             0.56 |                   0.16535 |          0.198   |      0.36345 |
| 46 |                0.18535  |       0.2218   |    0.40715 |                 0.2168 |                           0.0235 |                            0.0774 |                     0.1159  |                             0.56 |                   0.1649  |          0.19725 |      0.36215 |
| 47 |                0.1854   |       0.2219   |    0.4073  |                 0.2168 |                           0.0235 |                            0.0779 |                     0.1153  |                             0.56 |                   0.16575 |          0.1975  |      0.36325 |
| 48 |                0.18535  |       0.2218   |    0.40715 |                 0.2167 |                           0.0235 |                            0.0775 |                     0.1157  |                             0.56 |                   0.16615 |          0.19915 |      0.36535 |
| 49 |                0.18535  |       0.2218   |    0.40715 |                 0.2167 |                           0.0235 |                            0.0775 |                     0.1157  |                             0.56 |                   0.1657  |          0.1979  |      0.3636  |
